[
  {
    "objectID": "posts/2023-06-02-updating-gptstudio/index.html",
    "href": "posts/2023-06-02-updating-gptstudio/index.html",
    "title": "On updating a chat assistant app for the RStudio IDE",
    "section": "",
    "text": "This post summarizes the challenges overcomed while trying to improve three areas of the ChatGPT addin (shiny app) from {gptstudio}.\nThe whole journey began quite unexpectedly for me. I was developing a shiny app for my work and decided to venture into writing JavaScript code. However, I felt that the autocomplete feature in the RStudio IDE wasn’t the best available. So, I decided to give VSCode a shot.\nAs I’m not well versed with JS (or VSCode), I was requesting a lot of help from ChatGPT. That’s when I stumbled upon the Genie extension, which integrates ChatGPT seamlessly into the IDE (provided you have a valid API key). That got me thinking: shouldn’t we have a similar integration for the RStudio IDE?\nIt turns out, I wasn’t the only one who had this idea. Version 0.1.0 of {gptstudio} was already on CRAN, so I decided to give its ChatGPT addin a try. To my surprise, it exceeded my expectations, and I was intrigued to explore it further. I enthusiastically checked out its GitHub repository and couldn’t resist giving it a well-deserved star. As I dug deeper, I made an unexpected discovery—an open issue with a help wanted label."
  },
  {
    "objectID": "posts/2023-06-02-updating-gptstudio/index.html#run-shiny-app-in-background---issue-64",
    "href": "posts/2023-06-02-updating-gptstudio/index.html#run-shiny-app-in-background---issue-64",
    "title": "On updating a chat assistant app for the RStudio IDE",
    "section": "Run Shiny App in Background - issue #64",
    "text": "Run Shiny App in Background - issue #64\n\nIsn’t that the guy from the R4DS slack channel? Also, I agree with him\n\nThis was the perfect issue to try to solve. Just a few days prior, I had watched a video discussing RStudio jobs for shiny apps. Although I couldn’t locate the video at the time of writing this, I did find a README file containing the relevant information.\nTo sum it up, I discovered that it is possible to launch an app as a background job and then open it from the R console. This functionality extends to shiny apps that are addins from a package. By doing this, you can have your background shiny app displayed in the Viewer pane of the RStudio IDE.\nAfter trying this in my fork of the package, I documented all my code and submitted a Pull Request to the maintainers, which was integrated in very short time. I was very happy with this but still thought that there some things that could be improved."
  },
  {
    "objectID": "posts/2023-06-02-updating-gptstudio/index.html#the-ui-should-resemble-a-chat",
    "href": "posts/2023-06-02-updating-gptstudio/index.html#the-ui-should-resemble-a-chat",
    "title": "On updating a chat assistant app for the RStudio IDE",
    "section": "The UI should resemble a chat",
    "text": "The UI should resemble a chat\nEven though at the moment you were able to have your chat assistant, the UI was a bit awkward to navigate when you had a long chat history. I had the intention to just move the text input to the bottom of the app, like in a chat window. In order to do that, I thought that I should incorporate shiny modules and separate the app into smaller, more manageable components. Okay, this was a couple more lines of code than I expected. After that, I thought that the viewer pane was very small to have a lot of controls always visible and decided to hide some inputs in a “Configuration” dropdown button.\nBut shiny doesn’t have native dropdown buttons. Should I import bs4Dash just to have them? Should I make my own? Maybe the theme colors are a bit weird. Should I change them? How on earth will I test all these changes? Will the previous tests even pass? I would love to have the app’s theme match the RStudio IDE theme of every user. I would also love to provide a welcome message to the users. Oh man, I would totally love to have a “Copy” button on every code chunk provided in the responses (this was the hardest thing to get done).\nIn the end, the small contribution I intended to make was 59 commits long, and I won’t even say how many files were affected. I was very hesitant to make a pull request for something nobody had asked for, so I went for the “Discussions” tab.\n\nMe: Hey guys, I did this. I haven’t done a PR yet because no one really asked for this…\n\n\nJamesHWade: This is fantastic! I would very much welcome a PR. Great work!!!\n\n\nMichelNivard: Amazing! Yes, please submit a PR. I would love this!\n\nOkay then. Pull request merged!! So, what was the difficult part? Here comes the code.\n\nThe copy button\nAs I said before, I really wanted to have a button to easily add any code chunk text to the user’s system clipboard. At the time, I was unsure about doing it in R or in JS. I’ll explain why.\nWhen you send a prompt to ChatGPT, it will, by default, respond in markdown. You can easily convert that to HTML with shiny::markdown() and render it dynamically. A minimal shiny app to do that would look like this:\n\nlibrary(shiny)\n\nask_chatgpt &lt;- function(prompt) {\n  # code to make the request\n}\n\nui &lt;- fluidPage(\n  textInput(\"prompt\", \"Enter your prompt\"),\n  actionButton(\"send\", \"Send prompt\"),\n  uiOutput(\"response\")\n)\n\nserver &lt;- function(input, output, session) {\n  output$reponse &lt;- renderUI({\n    \n    ask_chatgpt(input$prompt) |&gt; \n      shiny::markdown()\n    \n  }) |&gt; \n    bindEvent(input$send)\n}\n\nshinyApp(ui, server)\n\nA flowchart representing this app would look like this:\n\n\n\n\n\nFigure 1: Flowchart of a minimal chat app\n\n\n\n\nThis receives a response, converts it to HTML, and sends it to the browser to be displayed. Every code chunk present would be wrapped inside a &lt;pre&gt; HTML tag, and because we aim to prepend a copy button to them, this tag should be the selector for any future manipulation.\nNow, we need to decide whether to do it in R or in JS. My first instinct was to do it via JS once the full answer was rendered. I would need a listener for a render event on any &lt;pre&gt; tag. This was my first attempt:\n\n$('pre').each(function() {\n  const $codeChunk = $(this);\n  const $copyButton = $('&lt;button&gt;').text('Copy');\n  $codeChunk.prepend($copyButton);\n\n  $copyButton.on('click', function() {\n    const codeText = $codeChunk.text();\n    navigator.clipboard.writeText(codeText);\n  });\n});\n\n\n\n\n\n\nThis can prepend a “Copy” button to a code chunk, but it doesn’t do it automatically after rendering. In fact, there is nothing in that code to handle the render event. I searched a lot for methods to achieve that, but unfortunately, I wasn’t able to find or understand the necessary code to implement it (remember that all this began because I wasn’t well-versed in JS). So, in the end, I would have to do it from R.\nSo, what is the best way to manipulate HTML tags in R? From my point of view, it is by using htmltools::tagQuery() and its corresponding methods. However, that function requires a tag(), tagList(), or a list() of tags. I didn’t have that. Compare these outputs:\n\nhtmltools::h1(\"Title 1\") |&gt; class()\n\n#&gt; [1] \"shiny.tag\"\n\nshiny::markdown(\"# Title 1\") |&gt; class()\n\n#&gt; [1] \"html\"      \"character\"\n\n\nWell then, can’t we just add the “shiny.tag” class to the rendered markdown to be able to use tagQuery()? Well…\n\ntag_example &lt;- shiny::markdown(\"# Title 1\")\nclass(tag_example) &lt;- c(class(tag_example), \"shiny.tag\")\n\nhtmltools::tagQuery(tag_example)\n\n#&gt; Error in list2env(xList, new.env(parent = emptyenv())): first argument must be a named list\n\n\nI invite you to try to understand that error message. I, however, decided not to try. What should we do now? Is there a way to convert an \"html\" character to an object that tagQuery() can handle? Not that I knew of. But, after a not-so-quick Google search, I came across this Github repo where Alan Dipert had shared a shiny app to handle that conversion. His code covered almost every tag conversion, but it didn’t work for all my tests and used the {XML} package, which was totally unfamiliar to me.\nI decided to implement a new version of the code with {xml2}, {glue}, and {purrr} at its core, which I managed to get working after several tries. You can see the code in this snapshot.\n\n\nCode\nlibrary(magrittr)\n\n#' Convert HTML to a Tag List\n#'\n#' This function takes a character string of HTML code and returns a tag list that can be used to\n#' display the HTML content in an R Markdown document or Shiny app. The resulting tag list can be\n#' passed as an argument to the `htmltools::tagQuery()` function or used as an input to other HTML\n#' rendering functions in R.\n#'\n#' @param html A character string of HTML code\n#' @return A tag list that can be used to display the HTML content\n#' @export\nhtml_to_taglist &lt;- function(html) {\n  html %&gt;%\n    html_to_r() %&gt;%\n    parse(text = .) %&gt;%\n    eval()\n}\n\n\n#' Convert HTML to R Code\n#'\n#' This function takes a character string of HTML code and returns a styled R code that can be used\n#' to recreate the HTML structure. The resulting R code is a character string that can be copied and\n#' pasted into an R script or console.\n#'\n#' @param html A character string of HTML code\n#' @return A character string of styled R code that can be used to recreate the HTML structure\n#' @export\nhtml_to_r &lt;- function(html) {\n  html %&gt;%\n    html_str_to_nodeset() %&gt;%\n    purrr::map(get_node_params) %&gt;%\n    purrr::map_chr(node_params_to_str) %&gt;%\n    glue::glue_collapse(sep = \", \") %&gt;%\n    into_taglist()\n}\n\n#' HTML string to xml nodeset\n#'\n#' This function takes HTML defined as a string and returns it as a xml_nodeset.\n#'\n#' @param str A character string that represents the HTML to be parsed\n#' @return A nodeset representing the parsed HTML\nhtml_str_to_nodeset &lt;- function(str) {\n  str %&gt;%\n    xml2::read_html() %&gt;%\n    xml2::xml_find_all(\"./body/*\")\n}\n\n\nnode_is_text &lt;- function(node) xml2::xml_name(node) == \"text\"\n\nnode_text_is_empty &lt;- function(node) xml2::xml_text(node, trim = TRUE) == \"\"\n\nnode_content_is_nodeset &lt;- function(node) \"xml_nodeset\" %in% class(node$contents)\n\nnode_content_is_empty &lt;- function(node) length(node$content) == 0\n\n#' Get Nodeset Tag Contents\n#'\n#' This function takes a nodeset and returns the contents of each tag.\n#'\n#' @param nodeset A nodeset representing a parsed HTML document\n#' @return A character vector containing the contents of each tag in the nodeset\nget_nodeset_tag_contents &lt;- function(nodeset) {\n  nodeset %&gt;%\n    xml2::xml_contents() %&gt;%\n    purrr::discard(\\(node) node_is_text(node) && node_text_is_empty(node))\n}\n\n\n#' Get Node Parameters\n#'\n#' This function takes a node and returns a list with its name, attributes, and contents.\n#' This functions applies recursively to every element of its contents until the element is plain text or has no extra content.\n#'\n#' @param node A node representing an element or text node in a parsed HTML document\n#' @return A list with the name, attributes, and contents of the node\n#'\nget_node_params &lt;- function(node) {\n  if (node_is_text(node)) {\n    list(\n      name = \"text\",\n      attrs = xml2::xml_attrs(node),\n      contents = xml2::xml_text(node)\n    )\n  } else {\n    node_with_params &lt;- list(\n      name = xml2::xml_name(node),\n      attrs = xml2::xml_attrs(node),\n      contents = get_nodeset_tag_contents(node)\n    )\n    if (node_content_is_nodeset(node_with_params) && !node_content_is_empty(node_with_params)) {\n      node_with_params$contents &lt;- node_with_params$contents %&gt;%\n        purrr::map(get_node_params)\n    }\n    node_with_params\n  }\n}\n\n\n#' Convert Attributes to Parameters\n#'\n#' This function takes a named character vector representing attributes and returns a character string\n#' that can be used as a parameter list in an HTML tag.\n#'\n#' @param attrs A named character vector representing attributes\n#' @return A character string that can be used as a parameter list in an HTML tag\nattrs_to_params &lt;- function(attrs) {\n  if (length(attrs) == 0) return(\"\")\n  params_names &lt;- names(attrs)\n  params_values &lt;- unname(attrs)\n  params &lt;- glue::glue(\"`{params_names}` = \\\"{params_values}\\\"\")\n  glue::glue_collapse(params, \", \")\n}\n\n\n#' Convert Node Parameters to String\n#'\n#' This function takes a list of parameters for an HTML tag and returns a character string that\n#' represents the tag with the given parameters. Aplies recursively to every child content until\n#' content is text or empty.\n#'\n#' @param node_params A list of parameters for an HTML tag\n#' @return A character string that represents the tag with the given parameters\n#'\nnode_params_to_str &lt;- function(node_params) {\n  if (node_params$name == \"text\") {\n    safe_text &lt;- gsub(\"'\", \"\\\\\\\\'\", node_params$contents)\n    glue::glue(\"'{safe_text}'\")\n  } else {\n    tag_name &lt;- glue::glue(\"htmltools::tags${node_params$name}\")\n    params &lt;- attrs_to_params(node_params$attrs)\n    contents &lt;- node_params$contents\n    if (length(contents) &gt; 0) {\n      contents &lt;- contents %&gt;%\n        purrr::map_chr(node_params_to_str) %&gt;%\n        glue::glue_collapse(sep = \", \")\n      # contents &lt;- paste0(\", \", contents)\n    } else {\n      contents &lt;- \"\"\n    }\n    fun_args &lt;- c(params, contents)\n    fun_args &lt;- fun_args[fun_args != \"\"]\n    fun_args &lt;- paste(fun_args, collapse = \", \")\n    glue::glue(\"{tag_name}({fun_args})\")\n  }\n}\n\n\n#' Paste tags string inside a tagList\n#'\n#' This function takes a list of HTML tags and returns a character string that, when evaluated,\n#' will produce a tagList object containing the given tags.\n#'\n#' @param tags_str A list of HTML tags\n#' @return A character string that, when evaluated, will produce a tagList object containing the given tags\ninto_taglist &lt;- function(tags_str) {\n  glue::glue(\"htmltools::tagList({tags_str})\")\n}\n\n\nAfter that, I was able to run the following:\n\nmd_example &lt;- \"# Title\\n\\nSome paragraph content.\\n\\n```\\n# some code content\\n```\"\nmd_rendered &lt;-shiny::markdown(md_example)\nmd_translated &lt;- html_to_taglist(md_rendered)\n\ntq_example &lt;- htmltools::tagQuery(md_translated)\n\ntq_example\n\n#&gt; `$allTags()`:\n#&gt; &lt;h1&gt;Title&lt;/h1&gt;\n#&gt; &lt;p&gt;Some paragraph content.&lt;/p&gt;\n#&gt; &lt;pre&gt;\n#&gt;   &lt;code&gt;# some code content\n#&gt; &lt;/code&gt;\n#&gt; &lt;/pre&gt;\n#&gt; \n#&gt; `$selectedTags()`: `$allTags()`\n\n\nThis meant that I was able to use tagQuery()! With this, prepending a copy button is not so difficult. You just need a combination of htmltools::tags$button() and tq$children('pre')$before(). Of course, you also need to handle the copy action in JS, which was already done in the first attempt. So, all of this was integrated into the development version of {gptstudio}.\nAt this point, the flowchart of the app would look like this:\n\n\n\n\n\nFigure 2: Flowchart including translation to shiny.tag\n\n\n\n\nNow, let’s take a look at what happens when we compare the character contents of md_rendered and md_translated.\n\nas.character(md_rendered)\n\n#&gt; [1] \"&lt;h1&gt;Title&lt;/h1&gt;\\n&lt;p&gt;Some paragraph content.&lt;/p&gt;\\n&lt;pre&gt;&lt;code&gt;# some code content\\n&lt;/code&gt;&lt;/pre&gt;\\n\"\n\nas.character(md_translated)\n\n#&gt; [1] \"&lt;h1&gt;Title&lt;/h1&gt;\\n&lt;p&gt;Some paragraph content.&lt;/p&gt;\\n&lt;pre&gt;\\n  &lt;code&gt;# some code content\\n&lt;/code&gt;\\n&lt;/pre&gt;\"\n\n\nMy translation inserts unnecessary white space between the opening of the &lt;pre&gt; and the &lt;code&gt; tags. This results in a weird “indentation” on the first line of every code chunk. This didn’t break the app’s behavior but it was ugly, and I wasn’t really sure why this was happening or how to fix it.\nFortunately, Iakov Davydov took notice of it and, in addition to fixing the translation, actually implemented the copy button mechanism in JS, super-seeding my translation efforts. This person also wrote the original attempt at using the “Enter” key as an alternative to clicking the “Send” button.\nWith this, the app could be represented with the following flowchart:\n\n\n\n\n\nFigure 3: Flowchart including JS process\n\n\n\n\nOf course, this is a lot simpler. All of this was added in the development version of the package, and my translation code had to be removed. This was bittersweet because it wasn’t too easy to achieve, but I understood that it was for the better."
  },
  {
    "objectID": "posts/2023-06-02-updating-gptstudio/index.html#receiving-a-response-shouldnt-take-too-long",
    "href": "posts/2023-06-02-updating-gptstudio/index.html#receiving-a-response-shouldnt-take-too-long",
    "title": "On updating a chat assistant app for the RStudio IDE",
    "section": "Receiving a response shouldn’t take too long",
    "text": "Receiving a response shouldn’t take too long\nAt this point we had a better looking app with friendlier input controls. But rendering a response was s-l-o-w. The app had to wait for the whole answer before rendering it. If you look carefully at Figure 3 you’ll see that it represents a sequential flow. We need to wait for ask_chatgpt() to complete before doing anything with the response. But this is not the experience people have while using the original ChatGPT.\nIn the web, you can see the response being generated in real time almost word by word with a typewriter-like effect. In fact, my first assumption was that the ChatGPT web app received its full response much faster than I did with my API requests because of my slow (Peruvian) connection, and that once it had the full response, it rendered it with a typewriter-like animation to ease the user’s reading process.\nWell, I was totally wrong. It turns out that the API offers the option to stream the response. This means that you can get the response while it is being generated, chunk by chunk. So, the typewriter-like effect doesn’t actually exist, the response is being constantly rendered while the chunks arrive.\nSo, to get the same thing in {gptstudio} we should just activate the stream option right? Well, yes, but the flow described in Figure 3 can’t render the response while it is being streamed. This requires a two step solution that I’ll describe now.\n\n\n\n\n\n\nWarning\n\n\n\nBefore you continue reading this section, I want to say that what comes can be hard to understand. I’m focusing on providing clear explanations rather than precise ones. There are some additional processes going on in the chat app that I don’t talk about to avoid distractions.\nIn addition, I’m a Peruvian political scientist turned self-taught data analyst, not a computer scientist or a software engineer. So, be patient with me if I happen to have gaps in my programming knowledge, or if I don’t use technical terms with precision, or even if I don’t use English correctly. Having that clear, let’s continue.\n\n\n\nRead the stream in R\nAt this point in time, I’m not aware of any R project that uses streaming for the OpenAI API. Making traditional http requests is rather straight forward with {httr2}. In fact, the internals of {gptstudio} where all based on {httr} functions that were later translated to {httr2}. So, how can we use streaming for this project?\nThe API documentation provides a guide on how to stream completions. EZ, you just need to use the openai python library! I imagine there are ways to wrap that library and access it from an app to be used as an addin in RStudio, but I also imagine it would make the setup much more harder than it needs to be.\nThe OpenAI team also supports an official Node.js library, but it’s README file states that it doesn’t natively support streaming. So, no easy way to stream chat completions from JS either. It is worth mentioning that setting up a Node.js package to be used in the app would’ve still been very hard for me (remember that all these began with me being bad at writing JS code?). So R it is.\nAs I mentioned before, we were using {httr2} for every API interaction. This package provides a req_stream() function that aims to facilitate streaming and sounded really promising. But a problem arised quickly: the format of the streaming response was hard to process.\nTo illustrate the problem, let’s consider prompting “Count from 1 to 5” and receiving a chat completion response without streaming. After after assigning it to the resp_example object, it would look like this:\n\nresp_example\n\n#&gt; {\n#&gt;   \"metadata\": \"some-metadata\",\n#&gt;   \"choices\": [\n#&gt;     {\n#&gt;       \"message\": {\n#&gt;         \"role\": \"assistant\",\n#&gt;         \"content\": \"1, 2, 3, 4, 5\"\n#&gt;       }\n#&gt;     }\n#&gt;   ],\n#&gt;   \"other-metadata\": \"more-metadata\"\n#&gt; }\n\n\nThe real content of the response is located inside resp_example$choices[[1]]$message$content (markdown). The length of this string is directly proportional to the time it takes to receive the response. This operation is located in the ask_chatgpt() process in Figure 3.\nWhen we use httr2::req_stream() we receive the full response in chunks while they stream. If we provide the print function as a callback (to be applied at every chunk while it arrives) it would look like the following:\n\n\n#&gt; [1] \"{\\n  \\\"me\"\n#&gt; [1] \"tadata\\\"\"\n#&gt; [1] \": \\\"some\"\n#&gt; [1] \"-metada\"\n#&gt; [1] \"ta\\\",\\n  \"\n#&gt; [1] \"\\\"choice\"\n#&gt; [1] \"s\\\": [\\n \"\n#&gt; [1] \"   {\\n  \"\n#&gt; [1] \"    \\\"me\"\n#&gt; [1] \"ssage\\\":\"\n#&gt; [1] \" {\\n    \"\n#&gt; [1] \"    \\\"ro\"\n#&gt; [1] \"le\\\": \\\"a\"\n#&gt; [1] \"ssistan\"\n#&gt; [1] \"t\\\",\\n   \"\n#&gt; [1] \"     \\\"c\"\n#&gt; [1] \"ontent\\\"\"\n#&gt; [1] \": \\\"1, 2\"\n#&gt; [1] \", 3, 4,\"\n#&gt; [1] \" 5\\\"\\n   \"\n#&gt; [1] \"   }\\n  \"\n#&gt; [1] \"  }\\n  ]\"\n#&gt; [1] \",\\n  \\\"ot\"\n#&gt; [1] \"her-met\"\n#&gt; [1] \"adata\\\":\"\n#&gt; [1] \" \\\"more-\"\n#&gt; [1] \"metadat\"\n#&gt; [1] \"\"\n\n\nI assumed that was good enough. You can process the chunks as they arrive and apply some clever logic to pull out just the content of the response. This send me down a rabbit hole to get to that clever logic, and it turns out that processing an incomplete JSON with regular expressions is as fun as it sounds. Never forget this legendary quote:\n\nSome people, when confronted with a problem, think “I know, I’ll use regular expressions.” Now they have two problems.\nJamie Zawinski\n\nLooking for an alternative, I checked the OpenAI guide again, and I realized that the python library returns not the full response in chunks, but just the content in chunks that individually can be treated as JSON text. How do they do it?\nAnother rabbit hole looking at the guts of the openai python library. Nothing there suggests that they are doing anything extraordinary to read the stream in chunks of the content. But a nice thing in a python script (even if it is located inside a library) is that you can always see directly the packages it imports. There I found the requests library being imported, which pointed me to the very low level urllib3 library.\nWhat if we do the same exploration for R? {gptstudio} depends on {httr2}, which in turn depends on {curl}, which has libcurl as system requirement. Can libcurl do for {gptstudio} the same that urllib3 does for the openai python library? The answer is YES!!! I tried the curl example from the OpenAI docs with stream activated directly in the terminal.\ncurl https://api.openai.com/v1/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"model\": \"gpt-3.5-turbo\",\n    \"messages\": [{\"role\": \"user\", \"content\": \"Count from 1 to 5\"}],\n    \"stream\": \"true\"\n  }'\nAnd boom! It worked in the first try! And it gets better. It turns out that {curl} already provides the curl_fetch_stream() function to avoid messing directly with libcurl in the terminal. In fact, httr2::req_stream() makes use of that function, with the caveat that for some reason it streams the full response instead of the content, as I explained before.\nNow, if we just pass the print method as a callback for curl_fetch_stream(), the streaming chunks look like this:\n\n\n#&gt; {\n#&gt;   \"choices\": [\n#&gt;     {\n#&gt;       \"delta\": {\n#&gt;         \"content\": \"1, \"\n#&gt;       }\n#&gt;     }\n#&gt;   ],\n#&gt;   \"metadata\": \"some-metadata\",\n#&gt;   \"other-metadata\": \"more-metadata\"\n#&gt; } \n#&gt; {\n#&gt;   \"choices\": [\n#&gt;     {\n#&gt;       \"delta\": {\n#&gt;         \"content\": \"2,\"\n#&gt;       }\n#&gt;     }\n#&gt;   ],\n#&gt;   \"metadata\": \"some-metadata\",\n#&gt;   \"other-metadata\": \"more-metadata\"\n#&gt; } \n#&gt; {\n#&gt;   \"choices\": [\n#&gt;     {\n#&gt;       \"delta\": {\n#&gt;         \"content\": \" 3, \"\n#&gt;       }\n#&gt;     }\n#&gt;   ],\n#&gt;   \"metadata\": \"some-metadata\",\n#&gt;   \"other-metadata\": \"more-metadata\"\n#&gt; } \n#&gt; {\n#&gt;   \"choices\": [\n#&gt;     {\n#&gt;       \"delta\": {\n#&gt;         \"content\": \"4, \"\n#&gt;       }\n#&gt;     }\n#&gt;   ],\n#&gt;   \"metadata\": \"some-metadata\",\n#&gt;   \"other-metadata\": \"more-metadata\"\n#&gt; } \n#&gt; {\n#&gt;   \"choices\": [\n#&gt;     {\n#&gt;       \"delta\": {\n#&gt;         \"content\": \"5\"\n#&gt;       }\n#&gt;     }\n#&gt;   ],\n#&gt;   \"metadata\": \"some-metadata\",\n#&gt;   \"other-metadata\": \"more-metadata\"\n#&gt; }\n\n\nAs you can see, every chunk is the same, except for the content field. From this, is just a matter of reading each chunk as JSON and doing whatever we want with the content from the callback passed to curl_fetch_stream(). We can wrap that functionality in a stream_chatgpt() function to slightly modify the current flow of the app.\n\n\n\n\n\nFigure 4: Flowchart including stream\n\n\n\n\nEven though we are able to read the content chunk by chunk, we are still waiting for the whole content to arrive before rendering something to the browser. That’s that we need to tackle next.\n\n\nRender the stream without reactivity\nNow that we can receive the response as a stream, we need to talk about reactivity. There is no better explanation about this topic that the one Hadley Wickham provides in Mastering Shiny. The chapter about the reactive graph made me feel like I was unlocking a superpower, and I encourage everyone to give it a try.\nIn short, it explains how your inputs, reactive expressions and outputs are part of a big and clever reactive process (represented in the reactive graph) that dinamycally updates the data used in your app whenever a change is observed. However, we must have in mind that this process executes sequentially, meaning that R needs to complete one task before starting to work in a new one, as it happens in the flow represented by Figure 4.\nSo we need to render the chunks as they arrive while the reactive process is blocked by the unfinished stream. Having the R process blocked means that we can’t rely on reactives or observers to handle changes in the data present in our app or render the content of the streaming chunks.\nLuckily, the session object present in every server of a shiny app provides the sendCustomMessage() method to communicate with the browser. This means that we need to use that method inside of the callback provided to curl_fetch_stream() running inside stream_chatgpt(), and send to the browser the accumulated content that keeps arriving as individual chunks.\nI hope you can understand that tongue-twister better with the following figure:\n\n\n\n\n\nFigure 5: Flowchart with communication concurrent to stream\n\n\n\n\nAs you can see, we do the same thing that we did before, it just happens that now we do it chunk by chunk as they arrive. The copy button is still handled at the very end because there is really no need to do it chunk by chunk.\nAnd with this, you have a better looking chat app, with a copy button, that renders responses in real time."
  },
  {
    "objectID": "posts/2023-06-02-updating-gptstudio/index.html#final-thoughts",
    "href": "posts/2023-06-02-updating-gptstudio/index.html#final-thoughts",
    "title": "On updating a chat assistant app for the RStudio IDE",
    "section": "Final thoughts",
    "text": "Final thoughts\nAll of this began with an open issue in the package’s GitHub repository. If you are developing a project that you think could use some help from the public, going open source and announcing that you need help will drastically improve the chances of, well, getting help. Not only that, an open-source project has better chances of receiving feedback such as bug reports or feature requests.\nOn the other hand, don’t be afraid of forking an open-source project and trying to make changes to it. At the very least, you can put into practice the knowledge you already have by attempting to fix some of its issues, and in the best-case scenario, you will also learn a lot of new things while challenging yourself to extend the project’s features. While not everything you try will necessarily end up being used for the project, the practice and learning will remain with you for your future projects.\nFeel free to give it a try with:\n\ninstall.packages(\"gptstudio\")\n\nAny feedback on the Github repo will be greatly appreciated."
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "Blog",
    "section": "",
    "text": "Strengthen your no-code apps with R code: appsheet 0.1.0\n\n\n\n\n\n\n\nrweekly\n\n\npackage\n\n\nno-code\n\n\nappsheet\n\n\n\n\n\n\n\n\n\n\n\nSep 11, 2023\n\n\n8 min\n\n\n10/2/23, 9:25:48 PM\n\n\n\n\n\n\n  \n\n\n\n\nOn updating a chat assistant app for the RStudio IDE\n\n\n\n\n\n\n\nrweekly\n\n\n\n\n\n\n\n\n\n\n\nJun 2, 2023\n\n\n22 min\n\n\n10/2/23, 9:25:48 PM\n\n\n\n\n\n\n  \n\n\n\n\nMonitorear ejecución presupuestal desde R\n\n\n\n\n\n\n\n\n\n\n\n\nAug 9, 2022\n\n\n2 min\n\n\n10/2/23, 9:25:48 PM\n\n\n\n\n\n\n  \n\n\n\n\nBug arreglado en Calculadora Renacyt\n\n\n\n\n\n\n\n\n\n\n\n\nJul 23, 2022\n\n\n1 min\n\n\n10/2/23, 9:25:48 PM\n\n\n\n\n\n\n  \n\n\n\n\nDos paquetes para mapas peruanos\n\n\n\n\n\n\n\n\n\n\n\n\nOct 12, 2021\n\n\n2 min\n\n\n10/2/23, 9:25:48 PM\n\n\n\n\n\n\n  \n\n\n\n\nCódigo noob de JS\n\n\n\n\n\n\n\n\n\n\n\n\nApr 25, 2020\n\n\n2 min\n\n\n10/2/23, 9:25:47 PM\n\n\n\n\n\n\n  \n\n\n\n\nPropuesta para elegir preguntas en conferencia de prensa\n\n\n\n\n\n\n\n\n\n\n\n\nApr 18, 2020\n\n\n6 min\n\n\n10/2/23, 9:25:47 PM\n\n\n\n\n\n\n  \n\n\n\n\n¿Por qué debo dejar que usen mi trabajo?\n\n\n\n\n\n\n\n\n\n\n\n\nMar 10, 2020\n\n\n5 min\n\n\n10/2/23, 9:25:47 PM\n\n\n\n\n\n\n  \n\n\n\n\n¿Cómo hacer un gráfico de parlamento en R?\n\n\n\n\n\n\n\n\n\n\n\n\nJan 29, 2020\n\n\n5 min\n\n\n10/2/23, 9:25:48 PM\n\n\n\n\n\n\n  \n\n\n\n\nCédula Elecciones 2020 usando ggplot2 (parte 3)\n\n\n\n\n\n\n\n\n\n\n\n\nJan 24, 2020\n\n\n9 min\n\n\n10/2/23, 9:25:47 PM\n\n\n\n\n\n\n  \n\n\n\n\nCédula Elecciones 2020 usando ggplot2 (parte 2)\n\n\n\n\n\n\n\n\n\n\n\n\nJan 18, 2020\n\n\n6 min\n\n\n10/2/23, 9:25:47 PM\n\n\n\n\n\n\n  \n\n\n\n\nCédula Elecciones 2020 usando ggplot2 (parte 1)\n\n\n\n\n\nCódigo y explicación para generar una cédula de elecciones congresales - Diseño\n\n\n\n\n\n\nJan 15, 2020\n\n\n7 min\n\n\n10/2/23, 9:25:47 PM\n\n\n\n\n\n\n  \n\n\n\n\nInicios\n\n\n\n\n\nRazones para la creación de este blog\n\n\n\n\n\n\nJan 13, 2020\n\n\n5 min\n\n\n10/2/23, 9:25:47 PM\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2021-08-15-grafico-de-parlamento/index.html",
    "href": "posts/2021-08-15-grafico-de-parlamento/index.html",
    "title": "¿Cómo hacer un gráfico de parlamento en R?",
    "section": "",
    "text": "Para esta tarea vamos a hacer de uso dos paquetes principalmente: el viejo conocido tidyverse y también de ggpol, una extensión de ggplot2 desarrollada especialmente para este tipo de gráficos. ggforce nos servirá al final sólo para una mejora estética.\n\nlibrary(tidyverse)\nlibrary(ggpol)\nlibrary(ggforce)\n\nComo en todo gráfico que se realiza con ggplot2, necesitamos primero contar con un data.frame o tibble que contenga la información necesaria para construirlo. La fuente primaria de estos datos es la web de la ONPE, de donde se puede obtener el detalle de la votación por varios niveles de desagregación. Debido a que no es propósito de este post mostrar cómo hacer el scrapping de la información, ni el cálculo de las curules, voy a preferir un resumen que ya ha trabajado otra persona para graficar en base a ello.\nEn la web de José Incio podemos encontrar un cuadro de la distribución de escaños del nuevo congreso peruano. Debido a que esa información aún está actualizándose según el conteo de los votos que ONPE sigue realizando, quiero hacer uso de Sys.time() para mostrar la hora en que estoy escribiendo este post.\n\nSys.time()\n\n[1] \"2023-05-19 11:41:38 -05\"\n\n\nHaciendo uso del add-in Paste as tribble que el paquete datapasta incluye en RStudio, puedo obtenr el tibble congreso, que no es más que un copy/paste de la tabla elaborada por José Incio disponible a esta hora.\n\nvotos &lt;- tibble::tribble(\n                                          ~Partido, ~Escaños,\n                                  \"ACCION POPULAR\",      25L,\n                        \"ALIANZA PARA EL PROGRESO\",      22L,\n   \"FRENTE POPULAR AGRICOLA FIA DEL PERU - FREPAP\",      15L,\n                                  \"FUERZA POPULAR\",      15L,\n                               \"UNION POR EL PERU\",      13L,\n                  \"PARTIDO DEMOCRATICO SOMOS PERU\",      11L,\n                                    \"PODEMOS PERU\",      11L,\n  \"EL FRENTE AMPLIO POR JUSTICIA, VIDA Y LIBERTAD\",       9L,\n                                  \"PARTIDO MORADO\",       9L\n  )\n\nEl siguiente paso es mejorar el tibble de tal modo que nos permita realizar el gráfico deseado. Empezamos por agregarle un color a cada uno de los partidos presentes en el gráfico. Podemos guiarnos de una hoja de referencia para escoger los colores, tomando en cuenta los colores partidarios. Podemos unir los colores a los partidos haciendo uso de bind_cols()\n\ncongreso &lt;- tibble(\n  colores = c(\n  \"darkred\",\n  \"dodgerblue4\",\n  \"deepskyblue3\",\n  \"darkorange2\",\n  \"gold2\",\n  \"brown3\",\n  \"royalblue3\",\n  \"forestgreen\",\n  \"mediumpurple4\"\n)) %&gt;% \n  bind_cols(votos)\n\nAhora que contamos con los datos, simplemente realizamos el gráfico. Hacemos uso de geom_parliament() del paquete ggpol. Tan sólo necesitamos mapear dos argumentos:\n\nseats: la cantidad de escaños o asientos obtenidos\nfill: el nombre de los partidos\n\nAdemás de eso, usaremos scale_fill_manual() para utilizar nuestros colores personalizados y el nombre de los partidos en la leyenda del gráfico. Luego, coord_fixed() nos ayuda a preservar el ratio de aspecto del gráfico.\n\ngrafico &lt;- ggplot(congreso)+\n  geom_parliament(\n    aes(\n      seats = Escaños, \n      fill = Partido), \n    color = \"white\") +\n  scale_fill_manual(\n    values = congreso$colores, \n    labels = congreso$Partido) +\n  coord_fixed()\n\nprint(grafico)\n\nWarning: Using the `size` aesthetic in this geom was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` in the `default_aes` field and elsewhere instead.\n\n\n\n\n\n\n\n\n\nVemos que hemos obtenido el gráfico y los partidos aparecen pintados con los colores que hemos asignado. Sin embargo, aún es posible hacerle unas mejoras estéticas. Usamos theme_no_axes() del paquete ggforce para eliminar las líneas guía de nuestro plano cartesiano y quedarnos sólo con un marco negro. También usamos labs() para agregarle un título a nuestro gráfico y theme() para cambiar el tamaño de los elementos de nuestra leyenda.\n\ngrafico +\n  theme_no_axes() +\n  labs(\n    title = \"DISTRIBUCIÓN DE ESCAÑOS\") +\n  theme(\n    legend.text = element_text(\n      size=5),\n    legend.key.size = unit(\n      x = 3, \n      units = \"mm\"))\n\n\n\n\n\n\n\n\nYa tenemos un gráfico más presentable y sencillo de replicar."
  },
  {
    "objectID": "posts/2022-08-09-monitorear-ejecuci-n-presupuestal-desde-r/index.html",
    "href": "posts/2022-08-09-monitorear-ejecuci-n-presupuestal-desde-r/index.html",
    "title": "Monitorear ejecución presupuestal desde R",
    "section": "",
    "text": "Este post marca el lanzamiento oficial de un nuevo paquete para R llamado {perutranspaeconomica}. El paquete cuenta con sitio web oficial y repositorio en Github. Su objetivo es acceder a los datos de ejecución presupuestal de las unidades ejecutoras (entidades públicas) que operan en el país.\nEl paquete es mejor aprovechable para las personas que estén familiarizadas con el Portal de seguimiento a la ejecución de gasto presupuestal del Ministerio de Economía y Finanzas. Hasta el momento, sirve para hacer consultas a partir del 2012. Con el paso del tiempo (y con algo de apoyo de la comunidad) puede ampliarse para abarcar años anteriores.\nComo ejemplo, podemos ver cuánto se presupuesto y gastó en el año 2021 en todo el país. Comenzamos por cargar el paquete y la colección tidyverse para facilidad de tratamiento de los datos.\n\nlibrary(perutranspaeconomica)\nlibrary(tidyverse)\n\nPara hacer la consulta, podemos usar la función gasto(). Con esto obtenemos una tabla muy similar a la de la plataforma del MEF. Para apreciar mejor la información, la convierto en un objeto JSON.\n\ngasto(year = 2021) |&gt; \n    jsonlite::toJSON(pretty = TRUE)\n\nPara ver una evolución en el tiempo, podemos usar una consulta iterativa. Así aprovechamos mejor las oportunidades del paquete.\n\nconsulta &lt;- 2012:2021 |&gt; \n    map_dfr(~gasto(year = .x))\n\nconsulta\n\nPor último, podemos graficar los datos obtenidos. En este caso, para conocer la evolución en la ejecución presupuestal del Estado peruano desde el 2012 al 2021.\n\nconsulta |&gt; \n    ggplot(aes(year, avance_percent)) +\n    geom_line() +\n    geom_label(aes(label = avance_percent))\n\nComo se puede ver, la ejecución presupuestal ha sido superior al 80% en los últimos años, pero nunca alcanzó el 90% de lo presupuestado.\nSin usar el paquete habría sido necesario:\n\nNavegar la plataforma año por año\nPara cada año, descargar un archivo excel con la información\nJuntar todas las tablas en un solo archivo.\nProcesar la información y generar el gráfico\n\n¡El paquete permitió saltarse los tres primeros pasos! Una consulta más compleja hubiese requerido más tiempo repetido en los pasos 1 y 2. Este es un ejemplo simple para demostrar las posibilidades de usar la información que tenemos a la mano."
  },
  {
    "objectID": "posts/2021-10-12-dos-paquetes-para-mapas-peruanos/index.html",
    "href": "posts/2021-10-12-dos-paquetes-para-mapas-peruanos/index.html",
    "title": "Dos paquetes para mapas peruanos",
    "section": "",
    "text": "Por cuestiones de trabajo, en los últimos meses tuve necesidad de dibujar mapas y usar las cifras del Mapa de Pobreza 2018 del INEI. En ambos casos, conseguir que la data se encuentre en un formato ordenado que permita trabajar de manera sencilla no fue fácil de lograr.\nPara que otras personas no tengan que pasar por ese mismo entretenimiento, desarrollé dos paquetes que contienen la data lista para usar. De paso, creé la sección de proyectos en mi web, donde alojaré nuevos paquetes o apps que cree en el futuro. Cada paquete tiene su propia web y repositorio en Github.\nCon {perumapas} se puede obtener las geometrías necesarias para dibujar los mapas y con {perupobreza2018} se puede usar las cifras del mapa de pobreza, incluyendo una columna calculada de cifra de pobreza monetaria.\nA continuación, un ejemplo para ver cómo trabajan en conjunto.\n\nlibrary(perupobreza2018)\nlibrary(perumapas)\nlibrary(sf) # obligatorio para perumapas\nlibrary(tidyverse) # para transformación y gráficos\n\nCon {perumapas} es sencillo realizar mapas a nivel regional, provincial y distrital. Por ejemplo, el mapa de las regiones del Perú.\n\nmapa_regional %&gt;% \n    ggplot() +\n    geom_sf()\n\n\n\n\nEl mapa de los distritos de la provincia de Lima:\n\nmapa_distrital %&gt;% \n    filter(departamento == \"LIMA\", provincia == \"LIMA\") %&gt;% \n    ggplot() +\n    geom_sf()\n\n\n\n\nCon {perupobreza2018} podemos añadirle una capa de información a cualquier mapa distrital. Para ello, primero se hace un join/merge entre los datos.\n\npobreza_lima &lt;- mapa_distrital %&gt;% \n    filter(departamento == \"LIMA\", provincia == \"LIMA\") %&gt;% \n    left_join(pobreza2018, by = \"ubigeo\")\n\nCon este cruce, podemos colorear cada distrito según su cifra de pobreza monetaria.\n\npobreza_lima %&gt;% \n    ggplot() +\n    geom_sf(aes(fill = pobreza_monetaria))\n\n\n\n\nEvidentemente, también es posible usar los paquetes de manera independiente. El nivel de personalización de los mapas generados dependerá del conocimiento en R y el paquete {ggplot2} ."
  },
  {
    "objectID": "posts/2020-01-18-cedula-2020-ggplot2-parte-2/index.html",
    "href": "posts/2020-01-18-cedula-2020-ggplot2-parte-2/index.html",
    "title": "Cédula Elecciones 2020 usando ggplot2 (parte 2)",
    "section": "",
    "text": "En el post anterior mostramos cómo crear el “esqueleto” de la cédula. En este, en cambio, incluiremos el texto y los logos de los partidos. Primero lo primero, habilitamos los paquetes del tidyverse.\nlibrary(tidyverse)\nNos aseguramos de contar con los objetos creados en el paso anterior. Especialmente el objeto cedula, que contiene las instrucciones de nuestro “esqueleto”.\nls()\n\n[1] \"cedula\"          \"has_annotations\" \"instrucciones\"   \"preferencial\"   \n[5] \"rectangulos\"\nComenzaremos por crear un vector que contenga los nombres de los partidos políticos en contienda, basados en el orden que obtuvieron en el sorteo realizado por la ONPE para determinar la posición en la cédula. Lo llamamos partidos. .\npartidos &lt;- c(\n  \"EL FRENTE AMPLIO POR JUSTICIA, VIDA Y LIBERTAD\",\n  \"FUERZA POPULAR\",\n  \"JUNTOS POR EL PERU\",\n  \"PERU PATRIA SEGURA\",\n  \"TODOS POR EL PERU\",\n  \"ALIANZA PARA EL PROGRESO\",\n  \"PARTIDO MORADO\",\n  \"ACCION POPULAR\",\n  \"AVANZA PAIS – PARTIDO DE INTEGRACION SOCIAL\",\n  \"RENACIMIENTO UNIDO NACIONAL\",\n  \"PODEMOS PERU\",\n  \"UNION POR EL PERU\",\n  \"PARTIDO DEMOCRATICO SOMOS PERU\",\n  \"DEMOCRACIA DIRECTA\",\n  \"PARTIDO APRISTA PERUANO\",\n  \"PERU NACION\",\n  \"FRENTE POPULAR AGRICOLA FIA DEL PERU- FREPAP\",\n  \"PARTIDO POLITICO CONTIGO\",\n  \"PARTIDO POLITICO NACIONAL PERU LIBRE\",\n  \"VAMOS PERU\",\n  \"SOLIDARIDAD NACIONAL\",\n  \"PARTIDO POPULAR CRISTIANO - PPC\")\nDel mismo modo que utilizamos una secuencia para generar el objeto preferencial en la primera parte, generamos una secuencia para la ubicación de los nombres de los partidos. Esta vez, la generamos directamente dentro de geom_text(), la función que nos permite colocar texto en un gráfico de ggplot. Tengamos en cuenta que el argumento size cambiará según el tamaño en pixeles que le hayamos asignado al gráfico1.\ncedula &lt;- cedula +\n  geom_text(\n    aes(x = 0.8, \n        y = seq(\n          from = 27.8, \n          to = 2.6, \n          by = -1.2), \n        label = partidos),\n      fontface = \"bold\",\n      size = 1.5,\n      hjust = 0)\ncedula\nLo siguiente es incluir el título de la cédula. Para esto utilizamos nuevamente geom_text(). Esta vez será necesario utilizar un linebreak (\\n) para tener el texto en dos líneas.\ncedula &lt;- cedula +\n  geom_text(\n    aes(x = 7.5, \n        y = 30.6, \n        label = \"ELECCIONES CONGRESALES\\nEXTRAORDINARIAS 2020\"), \n    fontface = \"bold\",\n    size = 2.1,\n    lineheight = 0.8)\ncedula\nIncluyamos ahora las instrucciones que indican cómo votar. Nuevamente, geom_text() nos servirá para lograrlo. En esta ocasión incluiremos más de un linebreak en algunos casos.\ncedula &lt;- cedula +\n  geom_text(\n    aes(x = 6.3, \n        y = 29.6, \n        label = \"ORGANIZACIÓN POLÍTICA\"),\n    fontface = \"bold\",\n    size = 1.2)+\n  geom_text(\n    aes(x = 6.3,\n        y = 28.9,\n        label = \"MARQUE CON UNA CRUZ  +   O UN ASPA   X  DENTRO DEL RECUADRO DEL SÍMBOLO\\nDE SU PREFERENCIA\"),\n    size = 0.9) +\n  geom_text(\n    aes(x = 13.25,\n        y = 29.5,\n        label = \"VOTO\\nPREFERENCIAL\"),\n    fontface = \"bold\",\n    size = 1.05,\n    lineheight = 0.8) +\n  geom_text(\n    aes(x = 13.25,\n        y = 28.9,\n        label = \"SI DESEA COLOQUE DENTRO\\nDE LOS RECUADROS UNO O DOS\\nNÚMEROS DE LOS CANDIDATOS\\nDE SU PREFERENCIA\"),\n    size = 0.54,\n    lineheight = 0.9)\n\ncedula\n¡Cada vez estamos más cerca! El siguiente paso es incluir los logos de las agrupaciones políticas."
  },
  {
    "objectID": "posts/2020-01-18-cedula-2020-ggplot2-parte-2/index.html#footnotes",
    "href": "posts/2020-01-18-cedula-2020-ggplot2-parte-2/index.html#footnotes",
    "title": "Cédula Elecciones 2020 usando ggplot2 (parte 2)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nEn esta ocasión, el tamaño del gráfico es de 3 x 6.4 pulgadas, manteniendo la proporción del tamaño oficial.↩︎"
  },
  {
    "objectID": "posts/2020-04-18-propuesta-para-elegir-preguntas-en-conferencia-de-prensa/index.html",
    "href": "posts/2020-04-18-propuesta-para-elegir-preguntas-en-conferencia-de-prensa/index.html",
    "title": "Propuesta para elegir preguntas en conferencia de prensa",
    "section": "",
    "text": "Casi todos los días vemos las conferencias de prensa que el presidente brinda. En ellas nos da las nuevas cifras importantes acerca del avance del covid19, nuevas medidas del gobierno y respuestas a preguntas de la prensa. Respecto a este último punto, no se conoce de fuentes oficiales la metodología a través de la cuál se realiza la elección de preguntas de la prensa. No me ha parecido que se hayan estado escogiendo preguntas malas, pero me quedé con la duda.\nDecidí consultarle a internet. El único medio que reportó algo acerca del tema fue Líbero (muy para mi sorpresa), y en realidad se trató de un artículo acerca de un hilo en twitter realizado por Eloy Marchán.\n\n\n(1/4) ¿Cómo salen las preguntas que el presidente @MartinVizcarraC responde en las \"conferencias de prensa\" que da cada día?-Hay un chat de Whatsapp llamado \"Actividades Palacio\", lo administran los funcionarios Gabriela Carrillo y Juan Francisco Celis y tiene 172 integrantes. pic.twitter.com/Fc43JZRj3n\n\n— Eloy Marchán (@eloymarchan) 16 de abril de 2020\n\n\nEn pocas palabras, según su explicación, existe un grupo de Whatsapp integrado por funcionarios y periodistas de varios medios de comunicación a través del cual se les comunica qué medios podrán enviar sus preguntas, que luego son respondidas en la conferencia de prensa. Los medios son escogidos a través de un sorteo.\nEl asunto es que, según Marchán, no se sabe en qué consiste ese sorteo. Yo creo que es una duda razonable, e innecesaria de mantener porque podría tener una solución muy simple."
  },
  {
    "objectID": "posts/2020-04-18-propuesta-para-elegir-preguntas-en-conferencia-de-prensa/index.html#el-motivo",
    "href": "posts/2020-04-18-propuesta-para-elegir-preguntas-en-conferencia-de-prensa/index.html#el-motivo",
    "title": "Propuesta para elegir preguntas en conferencia de prensa",
    "section": "",
    "text": "Casi todos los días vemos las conferencias de prensa que el presidente brinda. En ellas nos da las nuevas cifras importantes acerca del avance del covid19, nuevas medidas del gobierno y respuestas a preguntas de la prensa. Respecto a este último punto, no se conoce de fuentes oficiales la metodología a través de la cuál se realiza la elección de preguntas de la prensa. No me ha parecido que se hayan estado escogiendo preguntas malas, pero me quedé con la duda.\nDecidí consultarle a internet. El único medio que reportó algo acerca del tema fue Líbero (muy para mi sorpresa), y en realidad se trató de un artículo acerca de un hilo en twitter realizado por Eloy Marchán.\n\n\n(1/4) ¿Cómo salen las preguntas que el presidente @MartinVizcarraC responde en las \"conferencias de prensa\" que da cada día?-Hay un chat de Whatsapp llamado \"Actividades Palacio\", lo administran los funcionarios Gabriela Carrillo y Juan Francisco Celis y tiene 172 integrantes. pic.twitter.com/Fc43JZRj3n\n\n— Eloy Marchán (@eloymarchan) 16 de abril de 2020\n\n\nEn pocas palabras, según su explicación, existe un grupo de Whatsapp integrado por funcionarios y periodistas de varios medios de comunicación a través del cual se les comunica qué medios podrán enviar sus preguntas, que luego son respondidas en la conferencia de prensa. Los medios son escogidos a través de un sorteo.\nEl asunto es que, según Marchán, no se sabe en qué consiste ese sorteo. Yo creo que es una duda razonable, e innecesaria de mantener porque podría tener una solución muy simple."
  },
  {
    "objectID": "posts/2020-04-18-propuesta-para-elegir-preguntas-en-conferencia-de-prensa/index.html#la-propuesta",
    "href": "posts/2020-04-18-propuesta-para-elegir-preguntas-en-conferencia-de-prensa/index.html#la-propuesta",
    "title": "Propuesta para elegir preguntas en conferencia de prensa",
    "section": "La propuesta",
    "text": "La propuesta\nEsta propuesta se basa en el supuesto de que es mejor hacer un sorteo de preguntas y no uno de medios de comunicación.\n\nPaso 1: Recolectar las preguntas\nPara esto se puede usar un servicio de recolección de formularios/encuestas, como el de Google Forms. Basta con tener dos campos de llenado en el formulario: uno de identificación y uno en el que se brinde el detalle de la pregunta.\nEl campo de identificación necesitaría que los medios ingresen una contraseña que previamente los funcionarios les hayan brindado. La contraseña es única por medio de comunicación y, para mayor seguridad, puede ser actualizada diariamente.\nEn el segundo campo de llenado los medios de comunicación ingresan sus preguntas. Se podría poner un límite de caracteres para asegurar que la pregunta no sea más larga que la respuesta que se brindará.\nAquí debajo pongo un formulario de ejemplo en el que sólo se puede llenar el campo de pregunta si se ingresa primero una contraseña adecuada. La contraseña de este formulario consiste de 16 caracteres alfanuméricos aleatorios.\n\nContraseña: sEcVwNCLpKqf8oH3\n\n\nCargando…\n\nDespués de llenar algunas preguntas en el formulario, obtuve la siguiente tabla. Esta tabla se irá actualizando conforme le lleguen nuevas preguntas.\n\n\nPara trabajar el ejemplo, tomaré las cuatro (4) observaciones que yo ingresé. Con un cambio en los encabezados y un nuevo formato la tabla se ve así.\n\n\n\nEjemploHoraContraseñaPregunta2020-04-17 22:34:32.967sEcVwNCLpKqf8oH3En vista de las observaciones emitidas por los especialistas Fulano, Mengana y Sotana acerca de la medida X, ¿cuál será la nueva estrategia del gobierno?2020-04-17 22:38:38.994sEcVwNCLpKqf8oH3Las periodistas Fulana y Mengana denunciaron los hechos 1 y 2 ocurridos en las regiones X y Z. ¿Qué medidas está tomando el ministerio A para prevenir que vuelvan a ocurrir?2020-04-17 22:40:27.624sEcVwNCLpKqf8oH3Los médicos de la provincia A de la región X denunciaron la falta de material en el hospital regional. ¿Desde cuándo se tenía conocimiento de este hecho y por qué no se logró enfrentar a tiempo?2020-04-17 22:42:12.543sEcVwNCLpKqf8oH3El funcionario Fulano ha declarado X en el medio A. ¿Es esta la postura oficial del gobierno?\n\n\nLa columna Hora se genera de manera automática en Google Forms e indica la hora y fecha en que fue ingresada la pregunta. Cuando cada medio tenga su contraseña, la columna Contraseña tendría contraseñas diferentes en cada fila.\n\n\nPaso 2: Sortear las preguntas\nUna vez obtenida la tabla de preguntas se debe realizar el sorteo y aquí viene el aporte principal de este artículo: el sorteo debe ser aleatorio y reproducible. Esto se puede lograr usando un valor semilla al momento de realizar el muestreo. En el siguiente bloque de código de R uso como valor semilla la fecha de hoy para obtener una muestra de dos observaciones de mi tabla de preguntas1.\n\nset.seed(18042020)\nmuestra &lt;- dplyr::sample_n(preguntas, size = 2)\nprint(muestra)\n\n\n\n\nPreguntasHoraContraseñaPregunta2020-04-17 22:42:12.543sEcVwNCLpKqf8oH3El funcionario Fulano ha declarado X en el medio A. ¿Es esta la postura oficial del gobierno?2020-04-17 22:38:38.994sEcVwNCLpKqf8oH3Las periodistas Fulana y Mengana denunciaron los hechos 1 y 2 ocurridos en las regiones X y Z. ¿Qué medidas está tomando el ministerio A para prevenir que vuelvan a ocurrir?\n\n\nAhora, cualquier persona que tenga acceso a la tabla de preguntas puede reproducir el resultado de mi “elección” aleatoria usando el valor semilla.\n\n\nPaso 3: Comunicar los resultados\nAdemás de contestar las preguntas que fueron escogidas, es necesario que se hagan públicos la tabla de preguntas y el valor semilla utilizado para el muestreo (compartir el código utilizado sería incluso más útil). Esto puede servir de oportunidad para compartirse de manera conjunta con un resumen indicando las preguntas escogidas y sus respectivas respuestas.\nLa “elección” de preguntas tendría que hacerse con el tiempo prudente para preparar respuestas satisfactorias y descartar preguntas repetidas o inútiles (riesgos latentes). En este artículo no se propone que se haga esta elección en medio de la conferencia de prensa.\n\n\nPaso 4: Repetir\nPara la siguiente conferencia de prensa basta con limpiar los registros anteriores o filtrarlos de acuerdo a la nueva fecha. En caso se de decida, podrían actualizarse las contraseñas de los medios.\n\n\nExtra: Tiempo usado\nPara crear el formulario en Google Forms demoré menos de diez minutos. El proceso de muestreo de la tabla con valor semilla fue practicamente instantáneo.\nEn el siguiente bloque uso código R para demostrar que se tarda mucho menos de un segundo crear una gran cantidad de contraseñas para medios de comunicación.\n\n# Creando conjunto de caracteres alfanumericos con\n# minúsculas, mayúsculas y números\nalfanumericos &lt;- c(letters, LETTERS, 0:9)\n\n# Creando función para replicar \n# creación de contraseña\ncrear_contraseñas &lt;- function(conjunto, numero) {\n  \n  replicate(numero, \n            paste0(sample(x = conjunto, \n                          size = 16, \n                          replace = TRUE), \n                   collapse = \"\")\n            )\n}\n\n# Cantidad de milisegundos requeridos \n# para crear n contraseñas\nmicrobenchmark::microbenchmark(\n  `300` = {crear_contraseñas(alfanumericos, 300)},\n  `500` = {crear_contraseñas(alfanumericos, 500)},\n  `1000`= {crear_contraseñas(alfanumericos, 1000)}\n    )\n\nUnit: milliseconds\n expr      min       lq     mean   median       uq       max neval\n  300 1.801001 1.884000 2.236111 1.967452 2.091251  8.926201   100\n  500 2.974700 3.202051 3.630210 3.381851 3.685250  9.327401   100\n 1000 6.008501 6.324001 7.794788 6.736301 7.614100 22.179302   100\n\n\nViendo el cruce de la fila “1000” con la columna “mean”, vemos que en promedio requiere poquísimos milisegundos crear 1000 contraseñas diferentes. Usando 16 caracteres alfanuméricos, es posible obtener hasta \\(62^{16}\\) contraseñas únicas (equivalente a \\(4.76*10^{28}\\))."
  },
  {
    "objectID": "posts/2020-04-18-propuesta-para-elegir-preguntas-en-conferencia-de-prensa/index.html#footnotes",
    "href": "posts/2020-04-18-propuesta-para-elegir-preguntas-en-conferencia-de-prensa/index.html#footnotes",
    "title": "Propuesta para elegir preguntas en conferencia de prensa",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nUtilizo en un bloque oculto flextable::flextable() para imprimir la tabla con el formato adecuado.↩︎"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Samuel Calderon Serrano",
    "section": "",
    "text": "Twitter\n  \n  \n    \n     Github\n  \n  \n    \n     Linkedin\n  \n\n  \n  \n\nPresentación\nPolitólogo de la Universidad Antonio Ruiz de Montoya. Actualmente trabaja en la Superintendencia Nacional de Educación Universitaria - SUNEDU como miembro del Equipo Técnico Normativo de la Dirección de Licenciamiento. Su desempeño profesional ha sido siempre en el sector público, participando en iniciativas de recojo, análisis y sistematización de información con miras a mejorar la calidad de los servicios brindados a la ciudadanía.\nMiembro de la organización DecideBien, colabora ocasionalmente en iniciativas de código abierto. Durante los últimos meses, ha dictado talleres de Elaboración de Productos de Datos a profesionales de las ciencias sociales. Proviene de Lima, Perú.\nDescarga mi CV.\n\n\nIntereses\n\nDatos abiertos\nEducación superior\nEnseñanza de herramientas de uso de datos\n\n\n\nEducación\n\nBach. En Ciencia Política, 2016. Universidad Antonio Ruiz de Montoya.\n\n\n\n\n\n\n\n\n\nExperiencia\n\n\n\n\n\n\n\n\n\n\n\n\n\nIntegrante del Equipo Técnico Normativo de la Dirección de Licenciamiento\nSuperintendencia Nacional de Educación Universitaria\nAgo. 2020 - Actualidad. Lima\n\n\n  Responsabilidades:\n  \n  * Recopilación, análisis y sistematización de información sobre la educación superior a nivel nacional e internacional\n  * Modelo de Renovación de Licencia Institucional (Modelo 2.0)\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeguimiento al Plan Sectorial de Lucha contra la Corrupción\nMinisterio de Vivienda, Construcción y Saneamiento\nAbr. 2019 - Ago. 2020. Lima\n\n\nSeguimiento, sistematización, procesamiento y análisis de información, y elaboración de instructivos para la Oficina de Integridad y Lucha contra la Corrupción.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAsistente Académico de Capacitación\nEscuela Nacional de Administración Pública – ENAP\nOct. 2018 - Dic. 2018. Lima\n\n\nAsistencia académica presencial y virtual para la implementación, ejecución y evaluación de cursos de capacitación.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSupervisor de encuestadores\nMinisterio de Salud\nMay. 2018 - May. 2018. Lima\n\n\nSupervisión a encuestadores, procesamiento y análisis de consistencia de la información recogida en el Proyecto Termómetro Salud de la DGOS\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSupervisor de encuestadores\nMinisterio de Salud\nNov. 2017 - Dic. 2017. Lima\n\n\nSupervisión a encuestadores, procesamiento y análisis de consistencia de la información recogida en el Proyecto piloto Semáforo Salud de la DGOS\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOperador de aplicación de Encuestas\nInstituto Nacional de Estadística e Informática\nJun. 2016 - Set. 2017. Lima\n\n\nLevantamiento de información en hogares, procesamiento y análisis de consistencia de la información recogida en la Encuesta Nacional de Hogares – ENAHO"
  },
  {
    "objectID": "projects/packages/index.html",
    "href": "projects/packages/index.html",
    "title": "Paquetes para R",
    "section": "",
    "text": "perutranspaeconomica\n\n\nObtener datos del Portal de Transparencia Económica Perú desde R, con una interfaz de programación consistente y clara.\n\n\n\n\n\n\n\n\n\n\n\n\n\nperumapas\n\n\nGrafica mapas peruanos fácilmente con ggplot2.\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Proyectos",
    "section": "",
    "text": "Paquetes para R\n\n\nUna colección de paquetes creados por mí\n\n\n\n\n\n\n\n\n\n\n\n\n\nCalculadora RENACYT\n\n\nUna aplicación que permite obtener un cálculo de calificación y clasificación al registro RENACYT de acuerdo a la normativa más reciente (agosto 2021).\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2020-01-15-cedula-2020-ggplot2-parte-1/index.html",
    "href": "posts/2020-01-15-cedula-2020-ggplot2-parte-1/index.html",
    "title": "Cédula Elecciones 2020 usando ggplot2 (parte 1)",
    "section": "",
    "text": "No tengo conocimiento sobre el software que ha utilizado ONPE para diseñar la cédula que se utilizará en nuestras elecciones congresales, pero es posible intentar replicarla en R, usando funciones de la colección de paquetes del tidyverse.\nPara ello, primero cargamos los paquetes. Omitiré aquí los mensajes y warnings que aparecerán en una sesión normal. Además, en general utilizaré una línea por cada parámetro en las funciones que utilice, de modo que sea fácil de visualizar el código en teléfonos móviles.\n\nlibrary(tidyverse)\n\nEl siguiente paso será crear una superficie en la que irá el gráfico. Usaremos las funciones de ggplot2 para esto y para todas las futuras personalizaciones. Utilizaremos un ancho de 15 unidades (eje x) y un alto de 32 unidades (eje y) para mantener las proporciones definidas por la ONPE en la RESOLUCIÓN JEFATURAL Nº 000263-2019-JN/ONPE.\n\ncedula &lt;- ggplot()+\n  # límites del plano\n  xlim(c(0, 15))+\n  ylim(c(0, 32))\n\ncedula\n\n\n\n\nDebido a que las líneas divisorias y el fondo no nos ayudan para nuestros propósitos, nos vamos a deshacer de ellos usando theme_void(). Para mantener la referencia de los límites del gráfico, crearemos un marco con borde negro utilizando geom_rect().\n\ncedula &lt;- cedula +\n  theme_void() +\n    # marco rectangular con borde negro\n    geom_rect(aes(xmin = 0, \n                  xmax = 15, \n                  ymin = 0, \n                  ymax = 32), \n              color = \"black\", \n              alpha = 0)\n\ncedula\n\n\n\n\nLo siguiente es establecer el espacio que ocuparán los elementos de la cédula. En este caso, podemos llamar instrucciones a los marcos de texto que contienen las instrucciones de cómo votar. Los nombres de las columnas del tibble instrucciones nos permitirán identificarlos con los parámetros de geom_rect() cuando lo agreguemos al gráfico.\n\ninstrucciones &lt;- tribble(\n  ~xmin, ~xmax, ~ymin, ~ymax,\n  0.6,  11.8,  28.4,  29.9,\n  12.1,  14.4,  28.4,  29.9)\n\ncedula &lt;- cedula +\n    # contenedores debajo del título con instruciones\n    geom_rect(data = instrucciones, \n              aes(xmin = xmin, \n                  xmax = xmax,\n                  ymin = ymin, \n                  ymax = ymax), \n              alpha = 0.25)\ncedula\n\n\n\n\nLlamaremosrectangulos a los marcos en los que van contenidos los nombres de las agrupaciones políticas. Debido a que son varios contenedores y la distancia entre ellos es uniforme, crearemos los valores del eje Y usando un generador de secuencias. Los valores del eje X, en cambio, son constantes.\n\nrectangulos &lt;- tibble(xmin = 0.6, \n                      xmax = 11.8, \n                      ymin= seq(\n                        from = 27.3, \n                        to = 2.1, \n                        by = -1.2), \n                      ymax = ymin + 1)\n\ncedula &lt;- cedula +\n# rectángulos para nombres de partidos\n    geom_rect(data = rectangulos, \n              aes(xmin = xmin, \n                  xmax = xmax,\n                  ymin = ymin, \n                  ymax = ymax), \n              alpha = 0.15)\n\ncedula\n\n\n\n\nEl tibble preferencial contiene los cuadrados en los que el votante puede marcar el logo de la agrupación política de su preferencia. Modificando un poco su ubicación el eje X en dos ocasiones, permitirá tener también los cuadrados de voto preferencial.\n\npreferencial &lt;- tibble(\n  xmin = 10.8, \n  xmax = 11.8, \n  ymin= seq(\n    from = 27.3, \n    to = 2.1, \n    by = -1.2), \n  ymax = ymin + 1)\n\ncedula &lt;- cedula +\n  # cuadrados para logo \n  geom_rect(data = preferencial, \n            aes(xmin = xmin, \n                xmax = xmax,\n                ymin = ymin, \n                ymax = ymax), \n            color = \"black\", \n            fill = \"white\") +\n  # cuadrado para voto preferencial 1\n  geom_rect(data = preferencial, \n            aes(xmin = xmin + 1.3, \n                xmax = xmax + 1.3,\n                ymin = ymin, \n                ymax = ymax), \n            color = \"black\", \n            fill = \"white\") +\n  # cuadrado para voto preferencial 1\n  geom_rect(data = preferencial, \n            aes(xmin = xmin + 2.6, \n                xmax = xmax + 2.6,\n                ymin = ymin, \n                ymax = ymax), \n            color = \"black\", \n            fill = \"white\")\n\ncedula\n\n\n\n\nEn la segunda parte del post explicaré cómo agregar el texto, tanto de los nombres de los partidos políticos como de las instrucciones para votar."
  },
  {
    "objectID": "posts/2021-01-24-cedula-2020-ggplot2-parte-3/index.html",
    "href": "posts/2021-01-24-cedula-2020-ggplot2-parte-3/index.html",
    "title": "Cédula Elecciones 2020 usando ggplot2 (parte 3)",
    "section": "",
    "text": "En el post anterior logramos agregarle texto al esqueleto de nuestra cédula. Ahora debemos aprender a agregarle imágenes. Iniciamos, como siempre, haciendo uso de nuestros paquetes predilectos.\n\nlibrary(tidyverse)\n\n\nLo básico\nPara poder entender cómo se logra insertar los logos de los partidos políticos hace falta primero entender cómo insertar imágenes a un gráfico de ggplot2. Hasta la fecha, la forma más conveniente que he encontrado es haciendo uso de annotation_custom(). Esta función toma como primer argumento un grob, un objeto que sirve como bloque básico de construcción de todos los gráficos de ggplot2. Para lo que buscamos hacer, colocar los logos de los partidos dentro del gráfico, necesitamos convertir nuestras imágenes en grobs.\nPara que R interprete nuestras imágenes, hacemos uso de la función load.image() del paquete imager. Con el objeto obtenido hacemos uso de la función rasterGrob() del paquete grid, para obtener el grob necesario. Finalmente, annotation_custom() nos permite colocar el grob usando una sintaxis muy similar a la que hemos usado anteriormente con geom_rect(). Con el siguiente ejemplo, que usa el logo de esta página, debería quedar más claro.\n\nurl_ejemplo &lt;- \"https://upload.wikimedia.org/wikipedia/commons/thumb/6/68/Orange_tabby_cat_sitting_on_fallen_leaves-Hisashi-01A.jpg/800px-Orange_tabby_cat_sitting_on_fallen_leaves-Hisashi-01A.jpg\"\nimagen_ejemplo &lt;- imager::load.image(url_ejemplo)\ngrob_ejemplo &lt;- grid::rasterGrob(imagen_ejemplo)\n\nggplot()+\n  xlim(c(0,10))+\n  ylim(c(0,10))+\n  annotation_custom(grob = grob_ejemplo,\n                    xmin = 0, xmax = 10,\n                    ymin = 0, ymax = 10)\n\n\n\n\n\n\nLo real\nAhora que hemos entendido cómo funciona el procedimiento de agregar las imágenes, estamos listos para agregar los logos a nuestra cédula. Podríamos repetir el procedimiento anterior por cada partido en contienda, sin embargo, aprovechemos las ventajas de usar R para hacerlo más rápido (no necesariamente más sencillo).\nLo primero será tener los enlaces a todos los logos de los partidos. Esto es posible debido a que el portal Voto Informado cuenta con todos ellos. El vector logo_url fue creado manualmente para contener todos los logos, a excepción del de Todos por el Perú debido a que fue eliminado de la contienda por el JNE. En nuestro vector aparece como un NA.\n\nlogo_url &lt;- c(\n  \"https://votoinformado.jne.gob.pe/voto/Resources/imgs/logoop/2160.JPG\",\n  \"https://votoinformado.jne.gob.pe/voto/Resources/imgs/logoop/1366.JPG\",\n  \"https://votoinformado.jne.gob.pe/voto/Resources/imgs/logoop/1264.JPG\",\n  \"https://votoinformado.jne.gob.pe/voto/Resources/imgs/logoop/55.JPG\",\n  NA,\n  \"https://votoinformado.jne.gob.pe/voto/Resources/imgs/logoop/1257.JPG\",\n  \"https://votoinformado.jne.gob.pe/voto/Resources/imgs/logoop/2840.JPG\",\n  \"https://votoinformado.jne.gob.pe/voto/Resources/imgs/logoop/4.JPG\",\n  \"https://votoinformado.jne.gob.pe/voto/Resources/imgs/logoop/2173.JPG\",\n  \"https://votoinformado.jne.gob.pe/voto/Resources/imgs/logoop/5.JPG\",\n  \"https://votoinformado.jne.gob.pe/voto/Resources/imgs/logoop/2731.JPG\",\n  \"https://votoinformado.jne.gob.pe/voto/Resources/imgs/logoop/47.JPG\",\n  \"https://votoinformado.jne.gob.pe/voto/Resources/imgs/logoop/14.JPG\",\n  \"https://votoinformado.jne.gob.pe/voto/Resources/imgs/logoop/2191.JPG\",\n  \"https://votoinformado.jne.gob.pe/voto/Resources/imgs/logoop/32.JPG\",\n  \"https://votoinformado.jne.gob.pe/voto/Resources/imgs/logoop/2649.JPG\",\n  \"https://votoinformado.jne.gob.pe/voto/Resources/imgs/logoop/2646.JPG\",\n  \"https://votoinformado.jne.gob.pe/voto/Resources/imgs/logoop/2235.JPG\",\n  \"https://votoinformado.jne.gob.pe/voto/Resources/imgs/logoop/2218.JPG\",\n  \"https://votoinformado.jne.gob.pe/voto/Resources/imgs/logoop/2190.JPG\",\n  \"https://votoinformado.jne.gob.pe/voto/Resources/imgs/logoop/22.JPG\",\n  \"https://votoinformado.jne.gob.pe/voto/Resources/imgs/logoop/15.JPG\"\n)\n\nAhora que contamos con los enlaces, creamos una función que nos permita repetir el proceso de crear los grobs, de tal modo que podamos usarla sistemáticamente. La función que estamos creando, grob_url(), devuelve los valores NA. El argumento interpolate = TRUE dentro de grid::rasterGrob() ayuda a mejorar la calidad de la imagen.\n\ngrob_url &lt;- function(fileurl){\n  if(is.na(fileurl)) return(NA)\n  img &lt;- imager::load.image(fileurl)\n  grob &lt;- grid::rasterGrob(\n    img, \n    interpolate=TRUE)\n  \n  grob\n}\n\nAhora que contamos con una función que cumple nuestros objetivos, la aplicamos a todos los enlaces contenidos en logo_url. Para ello hacemos uso de la función map() del paquete purrr. Debido a que map() siempre nos devuelve una lista, usamos la función tibble() para crear un objeto tibble con una sola columna (grob), que contiene cada uno de nuestros grobs. Es el mismo nombre que el primer argumento de annotation_custom(), y tiene un motivo que descubriremos más adelante. El objeto grob ahora es una tabla que contiene listas en su única columna, pero nos permite trabajar con ella como si fuera cualquier data.frame normal.\n\ngrob &lt;- map(logo_url, grob_url) %&gt;% \n  tibble(grob = .)\n\nhead(grob)\n\n# A tibble: 6 × 1\n  grob      \n  &lt;list&gt;    \n1 &lt;rastrgrb&gt;\n2 &lt;rastrgrb&gt;\n3 &lt;rastrgrb&gt;\n4 &lt;rastrgrb&gt;\n5 &lt;lgl [1]&gt; \n6 &lt;rastrgrb&gt;\n\n\nAhora podemos hacer uso de annotation_custom() en cada uno de nuestros grobs. Recordemos los argumentos que esta función necesita:\n\ngrob: Es el grob que será dibujado en el gráfico.\nxmin: El primer valor del eje X, o posición de la esquina izquierda de la imagen.\nxmax: El segundo valor del eje X, o posición de la esquina derecha de la imagen.\nymin: El primer valor del eje Y, o posición de la esquina inferior de la imagen.\nymax: El segundo valor del eje Y, o posición de la esquina superior de la imagen.\n\nYa tenemos nuestros grobs mapeados en el tibble grob, ahora necesitamos los otros cuatro argumentos. Sin embargo, estos ya los teníamos desde hace muchísimo antes. Están contenidos en el tibble preferencial que creamos en la primera parte cuando usamos geom_rect() para dibujar los cuadros para voto preferencial.\n\nhead(preferencial)\n\n# A tibble: 6 × 4\n   xmin  xmax  ymin  ymax\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  10.8  11.8  27.3  28.3\n2  10.8  11.8  26.1  27.1\n3  10.8  11.8  24.9  25.9\n4  10.8  11.8  23.7  24.7\n5  10.8  11.8  22.5  23.5\n6  10.8  11.8  21.3  22.3\n\n\nEntonces, lo que necesitamos hacer ahora es unir ambos tibbles con bind_cols() del paquete dplyr(). Luego usamos filter() para librarnos del valor NA porque ya no es útil (de hecho, si lo dejamos ocasionaremos un bug que me costó más tiempo del debido identificar). Finalmente, utilizamos pmap() del paquete purrr para usar cada fila de nuestri tibble como lista de argumentos de annotation_custom(). Con esto, hemos conseguido la lista annotations con la que podemos graficar todos los logos.\n\nannotations &lt;- grob %&gt;% \n  bind_cols(preferencial) %&gt;% \n  filter(!is.na(grob)) %&gt;% \n  pmap(annotation_custom)\n\nSin embargo, unir todos los annotations no es tan sencillo como hacer cedula + annotations debido a que annotation_custom() no se comporta como un geom_*. Será necesario crear una función que nos permita hacer una suma recursiva de todos los elementos: rec_ggadd() toma un objeto de ggplot2 y una lista para añadir recursivamente sus elementos al objeto. El tercer argumento es un iterador que permite la recursividad, y no necesita ser identificado por quien use la función.\n\nrec_ggadd &lt;- function(ggobj, lista, i = length(lista)){\n  if(i == 1){\n    ggobj + lista[[i]]\n  } else {\n    ggobj &lt;- ggobj + lista[[i]]\n    rec_ggadd(ggobj, lista, i = i-1)\n  }\n}\n\nAhora sí, sólo queda aplicar la función a nuestra cedula y habremos conseguido lo que tanto deseábamos.\n\ncedula &lt;- rec_ggadd(cedula, annotations)\n\nImprimimos cedula para ver que todo salió bien.\n\ncedula\n\n\nggsave(\"cedula-parte-3.png\", cedula)\n\nSaving 3 x 6.4 in image"
  },
  {
    "objectID": "posts/2020-04-25-codigo-noob-de-js/index.html",
    "href": "posts/2020-04-25-codigo-noob-de-js/index.html",
    "title": "Código noob de JS",
    "section": "",
    "text": "Este es sólo un recordatorio de un código escrito en JavaScript mientras aprendía, para recordarle a mi yo futuro que ya debería conocer una mejor forma de hacerlo."
  },
  {
    "objectID": "posts/2020-04-25-codigo-noob-de-js/index.html#basic-algorithm-scripting-mutations",
    "href": "posts/2020-04-25-codigo-noob-de-js/index.html#basic-algorithm-scripting-mutations",
    "title": "Código noob de JS",
    "section": "Basic Algorithm Scripting: Mutations",
    "text": "Basic Algorithm Scripting: Mutations\nReturn true if the string in the first element of the array contains all of the letters of the string in the second element of the array.\nFor example, [“hello”, “Hello”], should return true because all of the letters in the second string are present in the first, ignoring case.\nThe arguments [“hello”, “hey”] should return false because the string “hello” does not contain a “y”.\nLastly, [“Alien”, “line”], should return true because all of the letters in “line” are present in “Alien”.\nfunction mutation(arr) {\n  // a minusculas las dos palabras\n  let arr2 = arr.map(el =&gt; el.toLowerCase());\n  // segunda palabra a array\n  let word2 = arr2[1].split(\"\");\n  // indice de aparicion de letra de palabra 2 en palabra 1\n  let indices = word2.map(el =&gt; arr2[0].search(el));\n  // test logico para ver si existe un '-1' en indices\n  let bool = indices.map(el =&gt; el &gt;= 0);\n  // se ordena el array bool y se obtiene el primer elemento\n  // si hay 'false' siempre estará delante\n  return bool.sort()[0];\n}\n\nlet res = mutation([\"Hello\", \"hey\"]);\n//let res2 = [true, false, true, false];\nconsole.log(res);\n\n\n&gt;false"
  },
  {
    "objectID": "posts/2020-01-13-inicios/index.html",
    "href": "posts/2020-01-13-inicios/index.html",
    "title": "Inicios",
    "section": "",
    "text": "Este blog se hace con la intención de compartir diferentes tipos de trabajo. Desde el año pasado emprendí la tarea de aprender el lenguaje R por mi cuenta, para ello me valí de varias plataformas en las que a través de artículos, videos, tutoriales y otros, he podido alcanzar un nivel más o menos avanzado en la comprensión del lenguaje."
  },
  {
    "objectID": "posts/2020-01-13-inicios/index.html#para-qué-un-blog",
    "href": "posts/2020-01-13-inicios/index.html#para-qué-un-blog",
    "title": "Inicios",
    "section": "",
    "text": "Este blog se hace con la intención de compartir diferentes tipos de trabajo. Desde el año pasado emprendí la tarea de aprender el lenguaje R por mi cuenta, para ello me valí de varias plataformas en las que a través de artículos, videos, tutoriales y otros, he podido alcanzar un nivel más o menos avanzado en la comprensión del lenguaje."
  },
  {
    "objectID": "posts/2020-01-13-inicios/index.html#la-importancia-de-rstudio",
    "href": "posts/2020-01-13-inicios/index.html#la-importancia-de-rstudio",
    "title": "Inicios",
    "section": "La importancia de RStudio",
    "text": "La importancia de RStudio\nQuiero resaltar que ha sido particularmente beneficioso que la comunidad que utiliza R es, además, especialmente activa en lo que respecta a enseñar a otros a utilizar dicha herramienta. Entre ellos destaco el trabajo que hace el equipo de RStudio, quienes además de desarrollar el IDE más utilizado actualmente para trabajar con R, han desarrollado una serie de paquetes que facilitan el acceso al mundo del famoso “Data Science” bajo la filosofía del tidyverse. Hago una mención honrosa al paquete blogdown, que me permite desarrollar esta web de una manera bastante sencilla."
  },
  {
    "objectID": "posts/2020-01-13-inicios/index.html#pequeña-reseña",
    "href": "posts/2020-01-13-inicios/index.html#pequeña-reseña",
    "title": "Inicios",
    "section": "Pequeña reseña",
    "text": "Pequeña reseña\nDebo decir que este no es mi primer intento de tener un espacio virtual. El año 2013, cuando estaba en mi tercer año universitario, junto a un grupo de la carrera desarrollamos en Wordpress un blog llamado Polinóptico que tenía la intención de ser un espacio en el que estudiantes de la carrera de Ciencia Política de la Universidad Antonio Ruiz de Montoya pudieran compartir sus trabajos y ser leídos por quien quisiera. Lamentablemente ese entusiasmo no llegó a la masa de estudiantes de la carrera, y el blog murió, no sin antes haber tenido varios intentos de ser revivido.\nEse mismo año llevé una clase de estadística dictada por José Incio en la que me fue bien. En esa clase conocí por primera vez el lenguaje R. Incio nos enseñaba conceptos de estadística descriptiva e inferencial ayudándose de scripts de R que tenía guardados, en algunas ocasiones editándolos en vivo para algún tipo de personalización, especialmente cuando se trataba de gráficos. A pesar de que trató de enseñarnos los beneficios de usar R, al final preferí prestar más atención al aprendizaje de SPSS en las clases de práctica porque resultaba más intuitivo y cercano a lo que ya conocía, Excel.\nEn los años siguientes, no tuve necesidad de usar ni Excel, ni SPSS, ni R para ningún trabajo de la universidad (no exagero), ni para ningún trabajo pagado eventual. La única excepción a esto fue la clase de Análisis de Regresión dictada por la gran Heidi Sada durante mi intercambio en la Ibero, Ciudad de México.\nEl 2014 alguien que no recuerdo ahora me presentó la plataforma Coursera en la que se podían llevar cursos MOOC de buena calidad y gratuitos. Después de llevar algunos por curiosidad, en setiembre del 2017 decidí llevar la “Data Science Specialization” de la Universidad de John Hopkins, que hacía uso intensivo de R en sus explicaciones. Fue mi segundo acercamiento al lenguaje y el primero al IDE RStudio. No terminé la especialización en Coursera porque los últimos módulos se me complicaron demasiado, y además ya tenía otro proyecto en mente.\nTodo este interludio sobre mi llegada a R es para decir que en el verano 2018 decidí tener un blog propio en Wordpress en el que haría tutoriales sobre R. Un plan bastante ambicioso para alguien que apenas había empezado a conocer lo más básico del lenguaje. Logré hacer dos entradas, la primera sobre cómo instalar R y la segunda sobre cómo instalar RStudio. La idea era ir aprendiendo R e ir haciendo tutoriales de lo que acababa de aprender. Nunca hice público el blog porque ahí murió. Nunca le agregué más contenido.\nLo que sí hice ese año fue estudiar estadística aplicada y SPSS en la escuela del INEI. Aunque aprendí bastante en estos cursos, el mayor uso que le encontré fue convencerme de que R era superior.\nFue recién en enero del 2019 que se juntaron varias cosas que me permitieron aprender realmente el lenguaje:\n\nNo tenía trabajo, por lo tanto tampoco tenía dinero para matricularme en cursos.\nMi enamorada se fue de viaje por varios meses y yo sentía que necesitaba tener el tiempo y la cabeza ocupados en algo productivo.\nEsta es más de ñoño. No me gusta salir en verano porque hace mucho calor en la calle y el sol es horrible, así que me la pasaba todo el tiempo en mi casa.\n\nAsí fue que terminé en tiempo récord el programa de estudios Data Scientist with R de la plataforma Datacamp e hice una shiny app para no olvidar lo que estaba aprendiendo.\nDurante el resto del año hice todo lo posible para usar R con cualquier excusa. En esto fue de gran ayuda conocer la existencia de RStudio.cloud porque me permitió usar R en el trabajo sin necesidad de pedir permiso a la oficina de tecnologías de la información para instalarlo.\nCreé este blog en setiembre 2019 para mantener activo mi conocimiento de las funciones de los paquetes blogdown y Rmarkdown. Este es el tercer intento de blog, y para asegurarme de que funcione, esta vez lo hago público el mismo día en que me compro el dominio. Si cuento con lectores estaré muy agradecido de que me hagan llegar sugerencias de temas a tratar en el futuro. No soy un politólogo que bloguea sobre R, sino un politólogo que usa R para bloguear."
  },
  {
    "objectID": "posts/2023-09-11-launching-appsheet/index.html",
    "href": "posts/2023-09-11-launching-appsheet/index.html",
    "title": "Strengthen your no-code apps with R code: appsheet 0.1.0",
    "section": "",
    "text": "This blog post serves two purposes:\nSo, let’s understand why no-code apps might be important for an R user."
  },
  {
    "objectID": "posts/2023-09-11-launching-appsheet/index.html#read-a-table",
    "href": "posts/2023-09-11-launching-appsheet/index.html#read-a-table",
    "title": "Strengthen your no-code apps with R code: appsheet 0.1.0",
    "section": "Read a table",
    "text": "Read a table\nThe first argument of appsheet() is a table name. By default, appsheet() will use the “Find” action, which reads all the rows. The following code is the equivalent of using appsheet(tableName = \"Driver\", Action = \"Find\").\n\nappsheet(\"Driver\")\n\n#&gt; # A tibble: 7 × 7\n#&gt;   `_RowNumber` Key      `Driver Name` Photo           Email `Phone Number` Jobs \n#&gt;   &lt;chr&gt;        &lt;chr&gt;    &lt;chr&gt;         &lt;chr&gt;           &lt;chr&gt; &lt;chr&gt;          &lt;chr&gt;\n#&gt; 1 2            70608c66 Driver 1      Driver_Images/… driv… 1-206-555-1000 db9e…\n#&gt; 2 3            261fadec Driver 2      Driver_Images/… driv… 1-206-555-1001 36a4…\n#&gt; 3 4            525982c5 Driver 3      Driver_Images/… driv… 1-206-555-1002 1db9…\n#&gt; 4 5            90eb1244 Driver 4      Driver_Images/… driv… 1-206-555-1003 e367…\n#&gt; 5 6            ddb26f78 Driver 5      Driver_Images/… driv… 1-206-555-1004 5420…\n#&gt; 6 7            29671cfb Driver 6      Driver_Images/… driv… 1-206-555-1005 98ed…\n#&gt; 7 8            7a6fafca Driver 7      Driver_Images/… driv… 1-206-555-1006 0b64…\n\n\nWhen the action is “Find”, you can take advantage of the Selector argument of ash_properties(), which can use some AppSheet internal functions to narrow the output.\n\nappsheet(\n    tableName = \"Driver\", \n    Properties = ash_properties(Selector = 'Filter(Driver, [Key] = \"70608c66\")')\n)\n\n#&gt; # A tibble: 1 × 7\n#&gt;   `_RowNumber` Key      `Driver Name` Photo           Email `Phone Number` Jobs \n#&gt;   &lt;chr&gt;        &lt;chr&gt;    &lt;chr&gt;         &lt;chr&gt;           &lt;chr&gt; &lt;chr&gt;          &lt;chr&gt;\n#&gt; 1 2            70608c66 Driver 1      Driver_Images/… driv… 1-206-555-1000 db9e…\n\n\nThe “Find” action is probably the one you’ll find yourself spending most time with"
  },
  {
    "objectID": "posts/2023-09-11-launching-appsheet/index.html#add-records-to-a-table",
    "href": "posts/2023-09-11-launching-appsheet/index.html#add-records-to-a-table",
    "title": "Strengthen your no-code apps with R code: appsheet 0.1.0",
    "section": "Add records to a table",
    "text": "Add records to a table\nThe “Add” action allows to add one or multiple records to a table. You must provide Rows, which can be a dataframe with the same column names as the specified table. You don’t need to provide all the columns to be successful, but can’t exclude the ones required by your app. Also, don’t try to add the _RowNumber(or Row ID when using an AppsSheet database), as it is generated internally.\nAn “Add” action returns a data.frame with the added rows when successful.\n\nrow_key &lt;- paste0(sample(letters, 8), collapse = \"\") # to be reused \n\nappsheet(\n    tableName = \"Driver\",\n    Action = \"Add\",\n    Rows = tibble::tibble(\n        Key = row_key, # required in app logic\n        `Email` = \"driverXX@company.com\" # required in app logic\n    ) \n)\n\n#&gt; # A tibble: 1 × 7\n#&gt;   `_RowNumber` Key      `Driver Name` Photo Email           `Phone Number` Jobs \n#&gt;   &lt;chr&gt;        &lt;chr&gt;    &lt;chr&gt;         &lt;chr&gt; &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;\n#&gt; 1 9            lcyieurm \"\"            \"\"    driverXX@compa… \"\"             \"\""
  },
  {
    "objectID": "posts/2023-09-11-launching-appsheet/index.html#update-records-from-a-table",
    "href": "posts/2023-09-11-launching-appsheet/index.html#update-records-from-a-table",
    "title": "Strengthen your no-code apps with R code: appsheet 0.1.0",
    "section": "Update records from a table",
    "text": "Update records from a table\nThe “Edit” action allow to update values from one or multiple records from a table, it also can target multiple columns. This one also requires the Rows argument. Again, you can’t use the _RowNumber column (but in this one you can use the Row ID generated by an Appsheet database).\nAn “Edit” action returns a data.frame with the whole content of the updated rows when successful.\n\nappsheet(\n    tableName = \"Driver\",\n    Action = \"Edit\",\n    Rows = tibble::tibble(\n        Key = row_key,\n        `Driver Name` = \"Some name\",\n        Photo = \"some/path.jpg\"\n    ) \n)\n\n#&gt; # A tibble: 1 × 7\n#&gt;   `_RowNumber` Key      `Driver Name` Photo         Email   `Phone Number` Jobs \n#&gt;   &lt;chr&gt;        &lt;chr&gt;    &lt;chr&gt;         &lt;chr&gt;         &lt;chr&gt;   &lt;chr&gt;          &lt;chr&gt;\n#&gt; 1 9            lcyieurm Some name     some/path.jpg driver… \"\"             \"\""
  },
  {
    "objectID": "posts/2023-09-11-launching-appsheet/index.html#delete-records-from-a-table",
    "href": "posts/2023-09-11-launching-appsheet/index.html#delete-records-from-a-table",
    "title": "Strengthen your no-code apps with R code: appsheet 0.1.0",
    "section": "Delete records from a table",
    "text": "Delete records from a table\nThe “Delete” action allows to delete one or multiple records from a table. This one also requires the Rows argument. Again, you can’t use the _RowNumber column (but in this one you can use the Row ID generated by an Appsheet database).\nA “Delete” action returns a data.frame with the deleted rows when successful.\n\nappsheet(\n    tableName = \"Driver\",\n    Action = \"Delete\",\n    Rows = tibble::tibble(\n        Key = row_key\n    ) \n)\n\n#&gt; # A tibble: 1 × 7\n#&gt;   `_RowNumber` Key      `Driver Name` Photo         Email   `Phone Number` Jobs \n#&gt;   &lt;chr&gt;        &lt;chr&gt;    &lt;chr&gt;         &lt;chr&gt;         &lt;chr&gt;   &lt;chr&gt;          &lt;chr&gt;\n#&gt; 1 9            lcyieurm Some name     some/path.jpg driver… \"\"             \"\""
  },
  {
    "objectID": "posts/2022-07-23-bug-arreglado-en-calculadora-renacyt/index.html",
    "href": "posts/2022-07-23-bug-arreglado-en-calculadora-renacyt/index.html",
    "title": "Bug arreglado en Calculadora Renacyt",
    "section": "",
    "text": "Este breve post describe un problema que se había encontrado en la Calculadora Renacyt.\nEn el mes de mayo de este año hice cambios en el repositorio para poder usar shiny modules, con la esperanza de que así fuera más solucionar cualquier problema en la aplicación.\nLamentablemente, esto introdujo un bug en la aplicación debido a un desafortunado error de tipeo que ocasionaba que la suma del puntaje total ignore el puntaje en formación académica y sume dos veces el puntaje en producción científica. Gracias a los reportes de Rolando Montenegro y Mg. Vitelio Asencios Tarazona pude localizar el problema y corregirlo. ¡Esa es la magia del código abierto!\nTambién quiero aprovechar para anunciar que la app estará siendo alojada en un nuevo servidor que no tiene límites de uso: https://apps.samuelenrique.com/calculadora-renacyt . La sección de proyectos de esta web ahora dirigirá a este enlace.\nEn el raro caso de que ese enlace falle, se puede seguir usando el anterior: https://samuelcalderon.shinyapps.io/caluladora-renacyt/\nSi alguien encuentra errores o es necesario actualizar la app, la manera más directa de encontrarme pos vía Twitter: https://twitter.com/samucalse"
  },
  {
    "objectID": "posts/2020-03-10-por-que-debo-dejar-que-usen-mi-trabajo/index.html",
    "href": "posts/2020-03-10-por-que-debo-dejar-que-usen-mi-trabajo/index.html",
    "title": "¿Por qué debo dejar que usen mi trabajo?",
    "section": "",
    "text": "El día de hoy ingresé, como ya se me está haciendo costumbre, a StackOverflow a ver si podía hacer algo para aumentar mis puntos de reputación. Como suele ocurrir en internet, uno empieza viendo una cosa y termina en un sitio bien diferente.\nLlegué a StackExchange Academia y vi una pregunta, que me pareció muy interesante. Una persona cuenta que trabajó mucho para realizar un trabajo de investigación para su tesis de postgrado, y que ahora su asesor le está pidiendo el código utilizado en su trabajo para que otra persona lo utilice. Me pareció interesante además que una de las etiquetas con las que esta persona marcó su pregunta fuera la de Propiedad intelectual."
  },
  {
    "objectID": "posts/2020-03-10-por-que-debo-dejar-que-usen-mi-trabajo/index.html#ser-autor-de-mi-trabajo-está-bien",
    "href": "posts/2020-03-10-por-que-debo-dejar-que-usen-mi-trabajo/index.html#ser-autor-de-mi-trabajo-está-bien",
    "title": "¿Por qué debo dejar que usen mi trabajo?",
    "section": "Ser autor de mi trabajo está bien",
    "text": "Ser autor de mi trabajo está bien\nNo cuesta mucho entender por qué. Si me pasé meses (o años) de duro trabajo para encontrar o construir los datos o procedimientos de análisis que me permitieron validar o refutar una hipótesis mía o de la comunidad científica, si le dediqué tanto tiempo, esfuerzo y rigurosidad a que mi trabajo sea de una calidad que me permita obtener una gran nota en mi presentación, si tuve que gastar mis escasos recursos y tiempo para obtener mi trabajo, es lógico que todo lo que se derive de ello sea mío. Yo no creo que pensar de esta manera sea egoísta.\nLa mayoría de instituciones que le dedican recursos a la investigación terminan publicando los resultados en algún tipo de reporte, libro, mapa, dashboard, medio de comunicación, redes sociales, etc. Nos llegamos a enterar de los resultados de las investigaciones a través de resúmenes ejecutivos o abstracts. Pero, ¿qué pasa si queremos verificar que la investigación siguió cierto estándar de calidad? Esto en general se refiere a los datos utilizados, desde su recolección hasta la metodología de análisis empleada. También me interesa averiguar si la persona que investigó obtuvo las conclusiones adecuadas respecto a los resultados de sus tests. Mientras más cercanas a la academia, las instituciones van aumentando su nivel de rigurosidad, y son mandatorios los marcos teóricos, capítulos de metodología, resultados y conclusiones. En el caso de las entidades públicas (y en general), se va haciendo cada vez más común que los conjuntos de datos utilizados en los análisis sean compartidos de manera pública. En el Perú, el INEI realiza esto a través de su portal de Microdatos y el Poder Ejecutivo muestra avances con su portal de Datos Abiertos.\nSin embargo, quiero atreverme a decir que esto no es suficiente. Cuando una persona se involucra en el análisis de datos, está realizando investigación, lo que significa que se encuentra una pregunta que quiere responder, se plantea una hipótesis al respecto y decide un método a través del cuál validará o rechazará su hipótesis. No hay investigación sin pregunta de investigación, ni hipótesis, ni metodología. Eso lo conocemos desde que asistimos a la primaria, porque es el método científico. En lo que nos quedamos cortos es en la reproducibilidad y la replicabilidad."
  },
  {
    "objectID": "posts/2020-03-10-por-que-debo-dejar-que-usen-mi-trabajo/index.html#replicable-o-reproducible",
    "href": "posts/2020-03-10-por-que-debo-dejar-que-usen-mi-trabajo/index.html#replicable-o-reproducible",
    "title": "¿Por qué debo dejar que usen mi trabajo?",
    "section": "¿Replicable o reproducible?",
    "text": "¿Replicable o reproducible?\nSegún el diccionario de Oxford, lo reproducible es algo que:\n\nPuede ser producido o hecho nuevamente de la misma manera1\n\nEn el caso de una investigación, nos referimos a que con el mismo conjunto de datos del análisis, realizando el mismo procedimiento, podemos obtener el mismo resultado. Esto hace que la calidad de la investigación tenga mayor facilidad de ser verificado por pares. Esta es una práctica bastante común en entornos que usan investigación estadística o a través de código.\nPor otro lado, lo replicable es algo que:\n\nPuede ser copiado exactamente2\n\nRoger D. Peng nos da un ejemplo de lo que esto significa en un contexto científico:\n\nSi dices que X causa Y, o que la Vitamina C agudiza una enfermedad, o que algo causa un problema, sucede que otros científicos, independientes de ti, tratarán de investigar la misma pregunta y ver si obtienen un resultado similar. Si muchas otras personas obtienen el mismo resultado y replican el hallazgo original, entonces tendemos a pensar que el hallazgo original probablemente fue verdadero, y que se trata de una relación o hallazgo real.3\n\nEn otras palabras, un estudio es replicado cuando al usar el mismo método de análisis en un nuevo conjunto de datos generados por el mismo diseño experimental, los resultados son similares.\nLa replicabilidad en sí no tiene nada de malo, es uno de los pilares del método científico y, en teoría, es aspirable. Sin embargo, es costosa. Recordemos que los resultados de los Censos 2017 en Perú fueron cuestionados desde el mismo día de la recolección de datos, por la gran cantidad de personas que reportaron no haber sido visitados por el personal de INEI. Pero, ¿quién podría replicar un censo?. Fuera de los límites legales, ¿qué persona o institución privada querría disponer 173.8 millones de soles en verificar que los resultados obtenidos sean los mismos que los del INEI?\nEvidentemente, un censo es un caso extremo. Pero podríamos cuestionar también la replicabilidad de encuestas de hogares, estudios económicos, tests de tratamientos experimentales, y un largo etcétera que incluye las encuestas de opinión que tanto aparecen en los medios de comunicación. A medida que aumenta nuestra necesidad (y capacidad) de obtener información, la replicabilidad se vuelve cada vez más difícil.\nEs por ello que la reproducibilidad se convierte en una alternativa viable. Esto no quiere decir que la replicabilidad deje de ser deseada. Si volvemos al caso de la pregunta que encontré en Stack Exchange, esta persona fue cuestionada por su asesor acerca de que otra persona pueda usar su código para su trabajo de investigación, en otras palabras, esta nueva persona estaba buscando replicar el trabajo, cosa que debería ser aceptada y promovida, porque es la mejor manera de hacer que la ciencia avance."
  },
  {
    "objectID": "posts/2020-03-10-por-que-debo-dejar-que-usen-mi-trabajo/index.html#footnotes",
    "href": "posts/2020-03-10-por-que-debo-dejar-que-usen-mi-trabajo/index.html#footnotes",
    "title": "¿Por qué debo dejar que usen mi trabajo?",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nTraducción propia de https://www.oxfordlearnersdictionaries.com/us/definition/english/reproducible?q=reproducible↩︎\nTraducción propia de https://www.oxfordlearnersdictionaries.com/definition/english/replicable?q=replicable↩︎\nTraducción propia de Peng, R. (2019) Report writing for Data Science in R. pg. 1. LeanPub.↩︎"
  }
]